{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines :  304713\n",
      "Conversations :  83097\n"
     ]
    }
   ],
   "source": [
    "#loading the data\n",
    "lines = []\n",
    "with open('cornall/movie_lines.txt') as infile:\n",
    "    for line in infile:\n",
    "        lines.append(line)\n",
    "        \n",
    "convs = []\n",
    "with open('cornall/movie_conversations.txt') as infile:\n",
    "    for line in infile:\n",
    "        convs.append(line)\n",
    "\n",
    "print \"Lines : \",len(lines)\n",
    "print \"Conversations : \",len(convs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304713 304713\n",
      "['L1045', 'L1044', 'L985', 'L984', 'L925'] ['They do not!\\n', 'They do to!\\n', 'I hope so.\\n', 'She okay?\\n', \"Let's go.\\n\"]\n"
     ]
    }
   ],
   "source": [
    "line_ids = []\n",
    "line_texts = []\n",
    "for line in lines:\n",
    "    line = line.split(' +++$+++ ')\n",
    "    line_ids.append(line[0])\n",
    "    line_texts.append(line[-1])\n",
    "\n",
    "print len(line_ids),len(line_texts)\n",
    "print line_ids[:5],line_texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['they do not',\n",
       " 'they do to',\n",
       " 'i hope so',\n",
       " 'she okay',\n",
       " 'let us go',\n",
       " 'wow',\n",
       " 'okay  you are gonna need to learn how to lie',\n",
       " 'no',\n",
       " 'i am kidding  you know how sometimes you just become this persona  and you do not know how to quit',\n",
       " 'like my fear of wearing pastels']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#text processing\n",
    "def text_processing(line):\n",
    "        line = line.strip().lower()\n",
    "        line = re.sub('i\\'m','i am',line)\n",
    "        line = re.sub('don\\'t','do not',line)\n",
    "        line = re.sub('won\\'t','would not',line)\n",
    "        line = re.sub('let\\'s','let us',line)\n",
    "        line = re.sub('he\\'s','he is',line)\n",
    "        line = re.sub('she\\'s','she is',line)\n",
    "        line = re.sub('you\\'re','you are',line)\n",
    "        line = re.sub('\\'d',' would',line)\n",
    "        line = re.sub('\\'ve',' have',line)\n",
    "        line = re.sub('it\\'s','it is',line)\n",
    "        line = re.sub('i\\'ll','i will',line)\n",
    "        line = re.sub('can\\'t','can not',line)\n",
    "        line = re.sub('that\\'ll','that will',line)\n",
    "        line = re.sub('\\'nt',' not',line)\n",
    "        line = re.sub('that\\'s','that is',line)\n",
    "        line = re.sub('what\\'s','what is',line)\n",
    "        line = re.sub('c\\'mon','come on',line)\n",
    "        line = re.sub('we\\'ve','we have',line)\n",
    "        line = re.sub('[^a-z\\s]','',line)\n",
    "        return line\n",
    "line_text_proc = [text_processing(line) for line in line_texts]\n",
    "line_text_proc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['L194', 'L195', 'L196', 'L197'],\n",
       " ['L198', 'L199'],\n",
       " ['L200', 'L201', 'L202', 'L203'],\n",
       " ['L204', 'L205', 'L206'],\n",
       " ['L207', 'L208']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#processing conversations\n",
    "convs_ids = []\n",
    "for line in convs:\n",
    "    line = line.strip().split(' +++$+++ ')[-1]\n",
    "    line = re.sub('[^L0-9]',' ',line).split()\n",
    "    convs_ids.append(line)\n",
    "convs_ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304713\n",
      "221616 221616\n",
      "can we make this quick  roxanne korrine and andrew barrett are having an incredibly horrendous public break up on the quad  again\n",
      "well i thought we would start with pronunciation if that is okay with you\n",
      "well i thought we would start with pronunciation if that is okay with you\n",
      "not the hacking and gagging and spitting part  please\n",
      "not the hacking and gagging and spitting part  please\n",
      "okay then how bout we try out some french cuisine  saturday  night\n",
      "you are asking me out  that is so cute what is your name again\n",
      "forget it\n",
      "no no it is my fault  we didnt have a proper introduction \n",
      "cameron\n"
     ]
    }
   ],
   "source": [
    "#create question and answer data\n",
    "id2line = {}\n",
    "for i in range(len(line_ids)):\n",
    "    id2line[line_ids[i]] = line_text_proc[i]\n",
    "print len(id2line)\n",
    "    \n",
    "questions = []\n",
    "answers = []\n",
    "for conv in convs_ids:\n",
    "    for i in range(len(conv)-1):\n",
    "        questions.append(id2line[conv[i]])\n",
    "        answers.append(id2line[conv[i+1]])\n",
    "\n",
    "print len(questions),len(answers)\n",
    "for i in range(5):\n",
    "    print questions[i]\n",
    "    print answers[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139121 139121\n"
     ]
    }
   ],
   "source": [
    "#remove questions and answers which are less than 2 words and greater than 20 words\n",
    "min_len = 2\n",
    "max_len = 20\n",
    "\n",
    "questions_temp = []\n",
    "answers_temp = []\n",
    "for i in range(len(questions)):\n",
    "    if len(questions[i].split()) >= min_len and len(questions[i].split())<= max_len:\n",
    "        questions_temp.append(questions[i])\n",
    "        answers_temp.append(answers[i])\n",
    "        \n",
    "questions = []\n",
    "answers = []\n",
    "for i in range(len(answers_temp)):\n",
    "    if len(answers_temp[i].split()) >= min_len and len(answers_temp[i].split()) <= max_len:\n",
    "        questions.append(questions_temp[i])\n",
    "        answers.append(answers_temp[i])\n",
    "        \n",
    "print len(questions),len(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8637 8637\n"
     ]
    }
   ],
   "source": [
    "#create a dictionary and take the words with at least 5 occurances\n",
    "freq_dist = nltk.FreqDist(' '.join(questions).split())\n",
    "word_list = sorted([(value,key) for key,value in freq_dist.items() if value >= 5],reverse = True)\n",
    "#map each word to a unique integer\n",
    "word2int = {}\n",
    "for value,key in word_list:\n",
    "    word2int[key] = len(word2int)\n",
    "\n",
    "#add unique tokens to dictionary\n",
    "codes = ['<PAD>','<UNK>','<GO>','<EOS>']\n",
    "for code in codes:\n",
    "    word2int[code] = len(word2int)\n",
    "    \n",
    "int2word = dict(zip(word2int.values(),word2int.keys()))\n",
    "print len(word2int),len(int2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 1, 121, 20, 30, 332, 31, 8634, 52, 10, 3, 94, 31, 0] ['well', 'i', 'thought', 'we', 'would', 'start', 'with', '<UNK>', 'if', 'that', 'is', 'okay', 'with', 'you']\n",
      "----------------------\n",
      "[7, 2, 8634, 15, 8634, 15, 7661, 416, 139, 8636] ['not', 'the', '<UNK>', 'and', '<UNK>', 'and', 'spitting', 'part', 'please', '<EOS>']\n",
      "-----------------------\n",
      "[7, 2, 8634, 15, 8634, 15, 7661, 416, 139] ['not', 'the', '<UNK>', 'and', '<UNK>', 'and', 'spitting', 'part', 'please']\n",
      "----------------------\n",
      "[94, 95, 35, 717, 20, 250, 46, 78, 1067, 8634, 1509, 149, 8636] ['okay', 'then', 'how', 'bout', 'we', 'try', 'out', 'some', 'french', '<UNK>', 'saturday', 'night', '<EOS>']\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "#convert text to integers\n",
    "questions_int = []\n",
    "answers_int = []\n",
    "\n",
    "for i in range(len(questions)):\n",
    "    temp = []\n",
    "    for word in questions[i].split():\n",
    "        if word2int.get(word,-1) == -1:\n",
    "            temp.append(word2int['<UNK>'])\n",
    "        else:\n",
    "            temp.append(word2int[word])\n",
    "    questions_int.append(temp)\n",
    "    temp = []\n",
    "    for word in answers[i].split():\n",
    "        if word2int.get(word,-1) == -1:\n",
    "            temp.append(word2int['<UNK>'])\n",
    "        else:\n",
    "            temp.append(word2int[word])\n",
    "    temp.append(word2int['<EOS>'])\n",
    "    answers_int.append(temp)\n",
    "for i in range(2):\n",
    "    print questions_int[i],[int2word[value] for value in questions_int[i]]\n",
    "    print \"----------------------\"\n",
    "    print answers_int[i],[int2word[value] for value in answers_int[i]]\n",
    "    print \"-----------------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
