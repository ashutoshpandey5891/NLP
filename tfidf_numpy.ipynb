{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9182869-bcf0-4fc2-804e-86ce9e9600c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "import sys\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6f52534-7b07-4f6b-99f7-442606b48779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -nc https://lazyprogrammer.me/course_files/nlp/bbc_text_cls.csv -P ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7861ac3e-81d8-446e-9c5a-58c7bbe13e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4b7b555-5bd4-4123-a7d9-185a3afbf767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2225, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    labels\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...  business\n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...  business\n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...  business\n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...  business\n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...  business"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/bbc_text_cls.csv')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29dafcb6-0073-4679-a3c6-b092eb94f35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {}\n",
    "tokened_docs = []\n",
    "idx_count = 0\n",
    "for text in data['text'].tolist():\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokened_doc = []\n",
    "    for token in tokens:\n",
    "        if token not in word2idx:\n",
    "            word2idx[token] = idx_count\n",
    "            idx_count += 1\n",
    "        tokened_doc.append(word2idx[token])\n",
    "    tokened_docs.append(tokened_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5f35e5d-e689-4513-9ac2-db111960f6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {v:k for k,v in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71c3852e-73eb-46f0-a71e-90e6bbd7bee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2225 34762\n"
     ]
    }
   ],
   "source": [
    "N = len(tokened_docs) ## Number of documents\n",
    "V = len(word2idx) ## Vocabulary size\n",
    "\n",
    "print(N,V)\n",
    "tf_array = np.zeros((N,V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61162630-b051-4f13-9cb1-dcecfef62487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sys.getsizeof(tf_array)/(1024*1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "051826c7-f7e6-4169-b811-d380183f9425",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,_doc in enumerate(tokened_docs):\n",
    "    for token in _doc:\n",
    "        tf_array[i,token] += 1\n",
    "        \n",
    "doc_freq = np.sum(tf_array > 0,axis=0)\n",
    "# print(doc_freq.shape)\n",
    "idf = np.log(N/doc_freq)\n",
    "tfidf_array = tf_array*idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54fe843b-b8bc-447c-bf12-5c4c99a310a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Choose random docs and get terms with highest tfidf scores in doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91cf93ab-7dd3-44bf-a075-6b63a22099cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web radio takes Spanish rap global  :  tech\n",
      "millan\n",
      "hip-hop\n",
      "rap\n",
      "latinohiphopradio.com\n",
      "spanish\n"
     ]
    }
   ],
   "source": [
    "rand_idx = np.random.choice(N)\n",
    "text,label = data.loc[rand_idx,'text'],data.loc[rand_idx,'labels']\n",
    "print(text.split('\\n')[0],' : ',label)\n",
    "array_row = tfidf_array[rand_idx]\n",
    "sorted_idxs = np.argsort(-array_row)\n",
    "top5 = sorted_idxs[:5]\n",
    "for idx in top5:\n",
    "    print(idx2word[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc53b75-755b-4734-9b02-bce1ac6d2b63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
